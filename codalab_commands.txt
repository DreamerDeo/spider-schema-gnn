# trained model files
mkdir trained_model
gsutil cp gs://gotit-models/gnn-bert/12Oct2019/bert-spider-full/best.th trained_model/model.th
gsutil cp gs://gotit-models/gnn-bert/best_discrim_model_full_spider_retrained_sqlonly.state.pth trained_model/reranker.th
gsutil cp gs://gotit-models/gnn-bert/12Oct2019/bert-spider-full/config.json trained_model/
gsutil cp -r gs://gotit-models/gnn-bert/12Oct2019/bert-spider-full/vocabulary trained_model/

# upload to codalab
# cl new russell_submission
cl work russell_submission
cl upload dataset_readers
cl upload models
cl upload modules
cl upload predictors
cl upload semparse
cl upload spider_evaluation
cl upload state_machines
cl upload rerank_beam_outputs.py
cl upload requirements.txt
cl upload predict.sh
cl upload trained_model
cl upload datasets/spider/dev_gold.sql

# start a run on codalab
cl run :dataset_readers :models :modules :predictors :semparse :spider_evaluation :state_machines :rerank_beam_outputs.py :requirements.txt "predict.sh:0x7517390c66f24fe9bc1c7d3502629821" :trained_model :database :dev_gold.sql "dataset:0xb357bf" "sh ./predict.sh dataset/dev.json predictions.sql" -n run-predictions --request-network --request-docker-image amolk/spider-submission:ready2 --request-time 120m --request-gpus 1 --request-memory 16g --request-disk 4g --request-queue tag=gotit

floydhub/pytorch:1.1.0-gpu.cuda9cudnn7-py3.45

##### Running locally in docker
# from gnn folder
docker run --gpus all -it \
-v `pwd`/datasets/spider:/workspace/dataset \
-v `pwd`/dataset_readers:/workspace/dataset_readers \
-v `pwd`/models:/workspace/models \
-v `pwd`/modules:/workspace/modules \
-v `pwd`/predictors:/workspace/predictors \
-v `pwd`/semparse:/workspace/semparse \
-v `pwd`/spider_evaluation:/workspace/spider_evaluation \
-v `pwd`/state_machines:/workspace/state_machines \
-v `pwd`/trained_model:/workspace/trained_model \
-v `pwd`/rerank_beam_outputs.py:/workspace/rerank_beam_outputs.py \
-v `pwd`/predict.sh:/workspace/predict.sh \
-v `pwd`/requirements.txt:/workspace/requirements.txt \
amolk/spider-submission:ready2 \
bash

##### Creating CodaLab worker #####
# Log into GCE instance
# Create a new GCE instance using OS Image "Deep Learning Image: PyTorch 1.1.0 and fastai m32"
# Docker is already installed with CUDA support
# Create a virtualenv to install python3 packages
# Install codalab and run worker

## Troubleshooting
# Follow https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04 to install docker
# install https://github.com/NVIDIA/nvidia-docker (`docker run --gpus all nvidia/cuda:9.0-base nvidia-smi` should succeed)
# Follow https://codalab-worksheets.readthedocs.io/en/latest/Execution/#running-your-own-worker to run a codalab worker
# Follow https://github.com/nvidia/nvidia-container-runtime#docker-engine-setup if you get error "Unknown runtime specified nvidia"
# `sudo apt install nvidia-container-runtime` -- if you get error "DockerException: Problem getting NVIDIA devices: 500 Server Error"


